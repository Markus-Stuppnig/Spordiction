{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "from time import sleep\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "\n",
    "li.append(pd.read_csv(\"../premier_league_2023.csv\", index_col=0))\n",
    "\n",
    "matches = pd.concat(li, axis=0, ignore_index=True)\n",
    "matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_premier_league_url(season_begin_year: int):\n",
    "\tdefault_url_prefix = \"https://fbref.com/en/comps/9/\"\n",
    "\tdefault_url_suffix = \"Premier-League-Stats\"\n",
    "\n",
    "\tif(season_begin_year > 2023):\n",
    "\t\traise ValueError(\"Year \" + str(season_begin_year) + \" didn't happen yet!\")\n",
    "\telif(season_begin_year == 2023):\n",
    "\t\treturn default_url_prefix + default_url_suffix\n",
    "\treturn default_url_prefix + str(season_begin_year) + \"-\" + str(season_begin_year + 1) + \"/\" + str(season_begin_year) + \"-\" + str(season_begin_year + 1) + \"-\" + default_url_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_urls(premier_league_url: str):\n",
    "\tpremier_league_data = requests.get(premier_league_url)\n",
    "\n",
    "\tif(premier_league_data.status_code != 200):\n",
    "\t\tprint(premier_league_data.status_code)\n",
    "\t\tretry_after = int(premier_league_data.headers['Retry-After'])\n",
    "\t\tprint(retry_after)\n",
    "\t\treturn\n",
    "\t\n",
    "\tpremier_league_soup = BeautifulSoup(premier_league_data.text)\n",
    "\tteams_table = premier_league_soup.select('table.stats_table')[0]\n",
    "\n",
    "\tlinks = list(filter(lambda x: x is not None, [l.get(\"href\") if \"squad\" in l.get(\"href\") else None for l in teams_table.find_all('a')]))\n",
    "\tteam_urls = [f\"https://fbref.com{l}\" for l in links]\n",
    "\n",
    "\treturn team_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_into_csv(all_matches: list, name: str):\n",
    "\tmatch_df = pd.concat(all_matches)\n",
    "\tmatch_df.columns = [c.lower() for c in match_df.columns]\n",
    "\tmatch_df.to_csv(name, na_rep='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches.sort_values(\"date\").dropna(subset=['date', 'result', 'gf'])\n",
    "matches = matches[~matches['date'].str.contains('2024')]\n",
    "all_matches = []\n",
    "all_matches.append(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_urls = get_team_urls(get_premier_league_url(season))\n",
    "\n",
    "index = 0\n",
    "for team_url in team_urls:\n",
    "\tsleep(4)\n",
    "\tteam_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n",
    "\n",
    "\tprint(\"Current year: \" + str(season) + \" in interval \" + str(season) + \"-\" + str(season))\n",
    "\tprint(\"Current team: \" + team_name + \" being \" + str(index + 1) + \"/\" + str(len(team_urls)))\n",
    "\tprint(team_url)\n",
    "\t\n",
    "\tteam_data = requests.get(team_url)\n",
    "\tteam_soup = BeautifulSoup(team_data.text)\n",
    "\n",
    "\tteam_links = [l.get(\"href\") for l in team_soup.find_all('a')]\n",
    "\t\n",
    "\tteam_links_shooting = [l for l in team_links if l and 'matchlogs/c9/shooting' in l] # Shooting\n",
    "\tteam_links_keeper = [l for l in team_links if l and 'matchlogs/c9/keeper' in l] # Goalkeeping\n",
    "\n",
    "\tschedule_html = pd.read_html(io.StringIO(team_data.text), match=\"Scores & Fixtures\")[0]\n",
    "\n",
    "\tsleep(4)\n",
    "\tshooting_data = requests.get(f\"https://fbref.com{team_links_shooting[0]}\")\n",
    "\tshooting_html = pd.read_html(io.StringIO(shooting_data.text), match=\"Shooting\")[0]\n",
    "\tshooting_html.columns = shooting_html.columns.droplevel()\n",
    "\n",
    "\tsleep(4)\n",
    "\tkeeper_data = requests.get(f\"https://fbref.com{team_links_keeper[0]}\")\n",
    "\tkeeper_html = pd.read_html(io.StringIO(keeper_data.text), match=\"Goalkeeping\")[0]\n",
    "\tkeeper_html.columns = keeper_html.columns.droplevel()\n",
    "\t\t\n",
    "\tdfs = [schedule_html, shooting_html, keeper_html]\t\t\n",
    "\n",
    "\tteam_data_end = reduce(lambda left,right: pd.merge(left,right,on='Date', suffixes=('', '_drop'), how='outer'), dfs)\n",
    "\tteam_data_end.drop([col for col in team_data_end.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\tteam_data_end[\"Season\"] = str(season) + \"-\" + str(season + 1)\n",
    "\tteam_data_end[\"Team\"] = team_name\n",
    "\n",
    "\tall_matches.append(team_data_end)\n",
    "\tindex += 1\n",
    "\tbreak\n",
    "\n",
    "all_matches[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"premier_league_\" + str(season) + \"new.csv\"\n",
    "write_list_into_csv(all_matches, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store duplicate indices\n",
    "all_duplicate_indices = []\n",
    "\n",
    "# Iterate through each DataFrame in the list\n",
    "for df in all_matches:\n",
    "    # Get duplicate indices for the current DataFrame\n",
    "    duplicate_indices = df[df.duplicated()].index.tolist()\n",
    "    # Append duplicate indices to the list\n",
    "    all_duplicate_indices.extend(duplicate_indices)\n",
    "\n",
    "# Convert the list to a set to remove duplicate indices\n",
    "all_duplicate_indices = list(set(all_duplicate_indices))\n",
    "\n",
    "# Print the indices of duplicate values\n",
    "print(\"Indices of duplicate values:\", all_duplicate_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
